device: cuda
dtype: float32
autocast: true
autocast_dtype: float16
seed: 2036
show: false
continue_from: //pretrained/facebook/musicgen-small
execute_only: null
execute_inplace: false
benchmark_no_load: false
efficient_attention_backend: torch
num_threads: 1
mp_start_method: forkserver
label: null
logging:
  level: INFO
  log_updates: 10
  log_tensorboard: true
  log_wandb: true
tensorboard:
  with_media_logging: false
  name: null
  sub_dir: null
wandb:
  with_media_logging: true
  project: V2M
  name: training1
  group: training
slurm:
  gpus: 8
  mem_per_gpu: 64
  time: 10080
  constraint: null
  partition: l40-gpu
  comment: null
  setup:
  - source ~/.bashrc
  - echo "FFMPEG located at $(which ffmpeg)"
  - echo "$(ffmpeg -version)"
  - cd /work/users/t/i/tis/VidMuse
  - source .venv/bin/activate
  exclude: null
  qos: gpu_access
  cpus_per_gpu: 4
  one_task_per_node: false
dora:
  dir: /checkpoint/${oc.env:USER}/experiments/audiocraft/outputs
  exclude:
  - device
  - wandb.*
  - tensorboard.*
  - logging.*
  - dataset.num_workers
  - eval.num_workers
  - special.*
  - metrics.visqol.bin
  - metrics.fad.bin
  - execute_only
  - execute_best
  - generate.every
  - optim.eager_sync
  - profiler.*
  - deadlock.*
  - efficient_attention_backend
  - num_threads
  - mp_start_method
  use_rendezvous: false
  git_save: true
datasource:
  max_sample_rate: 44100
  max_channels: 2
  train: egs/V2M20K/train
  valid: egs/V2M20K/valid
  evaluate: egs/V2M20K/eval
  generate: egs/V2M20K/eval
solver: musicgen
fsdp:
  use: false
  param_dtype: float16
  reduce_dtype: float32
  buffer_dtype: float32
  sharding_strategy: shard_grad_op
  per_block: true
profiler:
  enabled: false
deadlock:
  use: true
  timeout: 600
dataset:
  batch_size: 64
  num_workers: 3
  segment_duration: 29
  num_samples: null
  return_info: true
  shuffle: false
  sample_on_duration: false
  sample_on_weight: false
  min_segment_ratio: 0.8
  train:
    num_samples: 13293
    shuffle: true
    shuffle_seed: 0
    permutation_on_files: false
    merge_text_p: 0.25
    drop_desc_p: 0.5
    drop_other_p: 0.5
  valid:
    num_samples: 1899
  evaluate:
    num_samples: 1
  generate:
    num_samples: 1
    return_info: true
checkpoint:
  save_last: true
  save_every: 1
  keep_last: 1
  keep_every_states: null
generate:
  every: 1
  path: samples
  audio:
    format: wav
    strategy: loudness
    sample_rate: ${sample_rate}
    loudness_headroom_db: 14
  lm:
    use_sampling: true
    temp: 1.0
    top_k: 250
    top_p: 0.0
    prompted_samples: true
    unprompted_samples: true
    gen_gt_samples: false
    prompt_duration: null
    gen_duration: null
    remove_prompts: false
  num_workers: 5
evaluate:
  every: 1
  num_workers: 5
  truncate_audio: null
  fixed_generation_duration: null
  metrics:
    base: false
    fad: false
    kld: false
    text_consistency: false
    chroma_cosine: false
optim:
  epochs: 10
  updates_per_epoch: 208
  lr: 3.5e-05
  optimizer: adamw
  adam:
    betas:
    - 0.9
    - 0.95
    weight_decay: 0.1
    eps: 1.0e-08
  ema:
    use: true
    updates: 10
    device: cuda
    decay: 0.99
  max_norm: 1.0
  eager_sync: true
schedule:
  lr_scheduler: cosine
  step:
    step_size: null
    gamma: null
  exponential:
    lr_decay: null
  cosine:
    warmup: 4000
    lr_min_ratio: 0.0
    cycle_length: 1.0
  polynomial_decay:
    warmup: null
    zero_lr_warmup_steps: 0
    end_lr: 0.0
    power: 1
  inverse_sqrt:
    warmup: null
    warmup_init_lr: 0.0
  linear_warmup:
    warmup: null
    warmup_init_lr: 0.0
classifier_free_guidance:
  training_dropout: 0.3
  inference_coef: 3.0
attribute_dropout: {}
fuser:
  cross_attention_pos_emb: false
  cross_attention_pos_emb_scale: 1
  sum: []
  prepend: []
  cross:
  - description
  input_interpolate: []
conditioners:
  description:
    model: t5
    t5:
      name: t5-base
      finetune: false
      word_dropout: 0.3
      normalize_text: false
sample_rate: 32000
channels: 1
compression_model_checkpoint: //pretrained/facebook/encodec_32khz
compression_model_n_q: null
tokens:
  padding_with_special_token: false
interleave_stereo_codebooks:
  use: false
  per_timestep: false
cache:
  path: null
  write: false
  write_shard: 0
  write_num_shards: 1
metrics:
  fad:
    use_gt: false
    model: tf
    tf:
      bin: null
      model_path: //reference/fad/vggish_model.ckpt
  kld:
    use_gt: false
    model: passt
    passt:
      pretrained_length: 20
  text_consistency:
    use_gt: false
    model: clap
    clap:
      model_path: //reference/clap/music_audioset_epoch_15_esc_90.14.pt
      model_arch: HTSAT-base
      enable_fusion: false
  chroma_cosine:
    use_gt: false
    model: chroma_base
    chroma_base:
      sample_rate: ${sample_rate}
      n_chroma: 12
      radix2_exp: 14
      argmax: true
lm_model: transformer_lm
codebooks_pattern:
  modeling: delay
  delay:
    delays:
    - 0
    - 1
    - 2
    - 3
    flatten_first: 0
    empty_initial: 0
  unroll:
    flattening:
    - 0
    - 1
    - 2
    - 3
    delays:
    - 0
    - 0
    - 0
    - 0
  music_lm:
    group_by: 2
  coarse_first:
    delays:
    - 0
    - 0
    - 0
transformer_lm:
  dim: 1024
  num_heads: 16
  num_layers: 24
  hidden_scale: 4
  n_q: 4
  card: 2048
  dropout: 0.0
  emb_lr: null
  activation: gelu
  norm_first: true
  bias_ff: false
  bias_attn: false
  bias_proj: false
  past_context: null
  causal: true
  custom: false
  memory_efficient: true
  attention_as_float32: false
  layer_scale: null
  positional_embedding: sin
  xpos: false
  checkpointing: none
  weight_init: gaussian
  depthwise_init: current
  zero_bias_init: true
  norm: layer_norm
  cross_attention: false
  qk_layer_norm: false
  qk_layer_norm_cross: false
  attention_dropout: null
  kv_repeat: 1
  two_step_cfg: false
video:
  visual_encoder: clip
  video_fps: 2
  video_overlap: 0
  add_global:
    if_add_gobal: true
    global_feature_path: ''
    mode: average
    num_frames: 64
